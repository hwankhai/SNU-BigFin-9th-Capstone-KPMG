{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt(file_path):\n",
    "    \"\"\"\n",
    "    Reads content from a text file and returns it as a string\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the text file\n",
    "        \n",
    "    Returns:\n",
    "        str: Content of the text file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "nonfabricdetect  = \"prompt/nonfabricationhallucinationcheckingprompt.txt\"\n",
    "text_content = read_prompt(nonfabricdetect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_key = \"c1a527ba-8719-2649-bdb4-3ee5f4258862:fx\"\n",
    "translator = deepl.Translator(auth_key)\n",
    "\n",
    "\n",
    "def korean_translater(prompt):\n",
    "    \"\"\"\n",
    "    Translates the prompt to Korean\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Prompt to be translated\n",
    "        \n",
    "    Returns:\n",
    "        str: Translated prompt\n",
    "    \"\"\"\n",
    "    answer = translator.translate_text(prompt, target_lang=\"KO\")\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The question asks how the surgical benefits are paid when the insured has undergone multiple types of surgery simultaneously. The answer specifies that the benefit will be paid only for the one type of surgery that corresponds to the highest benefit amount. It also notes that if the surgeries are independent, with different medical treatment purposes and not on the same body part, each surgical benefit will be paid. Therefore, the corresponding specific payment policy detailed in the answer is: \"The benefit is paid only for the one type of surgery that corresponds to the highest benefit amount, unless the surgeries are independent and on different body parts.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Phase 1\n",
    "#Determine whether the QA is nonfabrication hallucination\n",
    "\n",
    "question = '피보험자가 동시에 여러 종류의 수술을 받은 경우 수술급여금은 어떻게 지급됩니까?'\n",
    "answer = '가장 높은 급여에 해당하는 한 종류의 수술에 대해서만 수술급여금을 지급합니다. 단, 동일한 신체부위가 아니며 의학적으로 치료목적이 다른 독립적인 수술인 경우에는 각각의 수술급여금을 지급합니다.'\n",
    "\n",
    "def nonfabrication_hallucination_checking(question, answer):\n",
    "    \n",
    "    context = {\n",
    "        'question': question,\n",
    "        'answer': answer\n",
    "    }\n",
    "    \n",
    "    nonfabricdetectprompt = read_prompt('prompt/nonfabricationhallucinationcheckingprompt.txt').format(**context)\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": nonfabricdetectprompt}\n",
    "        ]\n",
    "    )\n",
    "    answer = completion.choices[0].message.content\n",
    "    return answer\n",
    "    # if 'NONE' not in answer:\n",
    "    #     print(\"Phase 1 passed\")\n",
    "    #     return answer\n",
    "    # else:\n",
    "    #     print(\"질문과 관련이 없는 답변을 하는 할루시네이션\")\n",
    "    #     return answer\n",
    "    \n",
    "\n",
    "nonfabrication_hallucination_checking(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Phase 2-1 Step-wise Reasoning and Query Decomposition\n",
    "\n",
    "# def stepwise_reasoning_and_query_decomposition(question, answer):\n",
    "#     context = {\n",
    "#         'question': question,\n",
    "#         'answer': answer\n",
    "#     }\n",
    "    \n",
    "#     querydecomposition = read_prompt('prompt/QueryDecomposition.txt').format(**context)\n",
    "#     client = OpenAI()\n",
    "#     completion = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"user\", \"content\": querydecomposition}\n",
    "#         ]\n",
    "#     )\n",
    "#     answer = completion.choices[0].message.content\n",
    "    \n",
    "#     return answer\n",
    "\n",
    "\n",
    "# decomposition = stepwise_reasoning_and_query_decomposition(question, answer)\n",
    "# print(decomposition)\n",
    "\n",
    "\n",
    "#해당 방법은 RAG를 통해 이루어진 QA에 대해서 질문을 분해하기에느 적합하지 않기 때문에 사용하지 않는다.\n",
    "#다만, 답변을 생성할 때 참고한 문서는 Knowledge로 사용하여 다음 단계로 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 2-2 Knowledged Optimization\n",
    "\n",
    "def knowledge_optimization(question, knowledge):\n",
    "    context = {\n",
    "        'question': question,\n",
    "        'knowledge': knowledge\n",
    "    }\n",
    "    \n",
    "    knowledgeoptimization = read_prompt('prompt/KnowledgeOptimization.txt').format(**context)\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": knowledgeoptimization}\n",
    "        ]\n",
    "    )\n",
    "    answer = completion.choices[0].message.content\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer states that the insurance payment should be made within 3 business days from the date of document submission. The query asks for the general payment deadline after the submission of insurance claim documents, and the knowledge confirms that payment should be made within the same timeframe of 3 business days from the date of submission. Both the answer and the knowledge imply the same timeframe for payment. Therefore, the final judgment is CORRECT.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def judgment(question, knowledge, answer):\n",
    "    \n",
    "    query_knowledge = f'''#Query-1#: {question}\n",
    "#Knowledge-1#: {knowledge}\n",
    "    '''\n",
    "    \n",
    "    context = {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'query_knowledge': query_knowledge,\n",
    "    }\n",
    "    judgement = read_prompt('prompt/Judgment.txt').format(**context)\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": judgement}\n",
    "        ]\n",
    "    )\n",
    "    answer = completion.choices[0].message.content\n",
    "    \n",
    "    \n",
    "    return answer\n",
    "    # if 'INCONCLUSIVE' in answer:\n",
    "    #     print(\"Answer is inconclusive\")\n",
    "    #     return answer\n",
    "    # elif 'INCORRECT' in answer:\n",
    "    #     print(\"사실과 다른 할루시네이션\")\n",
    "    #     return answer\n",
    "    # else:\n",
    "    #     print('Phase 2 passed')\n",
    "    #     print(\"문제없음\")\n",
    "    #     return answer\n",
    "    \n",
    "\n",
    "question = \"보험금 청구 서류 접수 후 일반적인 경우 보험금 지급기한은 언제까지입니까?\"\n",
    "knowledge = \"그 서류를 접수한 날부터 3영업일 이내에 보험금을 지급하거나 보험료의 납입을 면제합니다.\"\n",
    "answer = \"서류 접수한 날부터 3영업일 이내에 보험금을 지급해야 합니다.\"\n",
    "\n",
    "judgment(question, knowledge, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 passed\n",
      "사실과 다른 할루시네이션\n",
      "무배당 1-5수술특약에서 피보험자가 별도의 보험수익자를 지정하지 않은 경우 계약자가 보험수익자가 된다는 답변이 있습니다. 그러나 제공된 지식은 이와 상반되게 별도의 수익자를 지정하지 않은 경우 피보험자가 수익자가 된다고 명시하고 있습니다. 따라서 이러한 모순으로 인해 정답에 대한 최종 판단은 올바르지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "def HallucinationDetection(question, knowledge, answer):\n",
    "    #Phase 1\n",
    "    #Determine whether the QA is nonfabrication hallucination\n",
    "    Phase_answer = nonfabrication_hallucination_checking(question, answer)\n",
    "    if 'NONE' in Phase_answer:\n",
    "        print(\"Non-Fabrication Hallucination\")\n",
    "        \n",
    "        return print(korean_translater(Phase_answer))\n",
    "    else:\n",
    "        print(\"Phase 1 passed\")\n",
    "    #Phase 2-1 Knowledged Optimization\n",
    "    OptimizedKnowledge = knowledge_optimization(question, knowledge)\n",
    "    \n",
    "    #Phase 2-2 Judgment\n",
    "    Judgment = judgment(question, OptimizedKnowledge, answer)\n",
    "    if 'INCONCLUSIVE' in Judgment:\n",
    "        print(\"Answer is inconclusive\")\n",
    "\n",
    "    elif 'INCORRECT' in Judgment:\n",
    "        print(\"사실과 다른 할루시네이션\")\n",
    "        return print(korean_translater(Judgment))\n",
    "    else:\n",
    "        print('Phase 2 passed')\n",
    "        print('할루시네이션 없음')\n",
    "        \n",
    "    \n",
    "\n",
    "question = \"무배당 1~5종수술특약에서 보험수익자를 별도로 지정하지 않았다면 보험수익자는 누가 됩니까?\"\n",
    "knowledge = \"이 계약에서 계약자가 보험수익자를 지정하지 않은 때에는 보험수익자를 피보험자로 합니다.\"\n",
    "answer = \"계약자가 보험수익자가 됩니다.\"\n",
    "\n",
    "\n",
    "HallucinationDetection(question, knowledge, answer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
